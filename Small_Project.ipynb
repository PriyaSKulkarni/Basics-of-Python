{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Let's consider a real-life scenario where you are analyzing customer feedback for a product. You have a large data set of customer reviews in the form of strings, and you want to extract useful information from them using the three identified tasks:\n",
        "\n",
        "Task 1. String in lowercase: You want to pre-process the customer feedback by converting all the text to lowercase. This step helps standardize the text. Lower casing the text allows you to focus on the content rather than the specific letter casing.\n",
        "\n",
        "Task 2. Frequency of all words in a given string: After converting the text to lowercase, you want to determine the frequency of each word in the customer feedback. This information will help you identify which words are used more frequently, indicating the key aspects or topics that customers are mentioning in their reviews. By analyzing the word frequencies, you can gain insights into the most common issues raised by customers.\n",
        "\n",
        "Task 3. Frequency of a specific word: In addition to analyzing the overall word frequencies, you want to specifically track the frequency of a particular word that is relevant to your analysis. For example, you might be interested in monitoring how often the word \"reliable\" appears in customer reviews to gauge customer sentiment about the product's reliability. By focusing on the frequency of a specific word, you can gain a deeper understanding of customer opinions or preferences related to that particular aspect.\n",
        "\n",
        "By performing these tasks on the customer feedback dataset, you can gain valuable insights into customer sentiment"
      ],
      "metadata": {
        "id": "nbPUIzoowjz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "givenstring=\"Lorem ipsum dolor! diam amet, consetetur Lorem magna. sed diam nonumy eirmod tempor. diam et labore? et diam magna. et diam amet.\""
      ],
      "metadata": {
        "id": "aLlao9o8wnty"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextAnalyzer(object):\n",
        "\n",
        "    def __init__ (self, text):\n",
        "        # remove punctuation\n",
        "        formattedText = text.replace('.','').replace('!','').replace('?','').replace(',','')\n",
        "\n",
        "        # make text lowercase\n",
        "        formattedText = formattedText.lower()\n",
        "\n",
        "        self.fmtText = formattedText\n",
        "\n",
        "    def freqAll(self):\n",
        "        # split text into words\n",
        "        wordList = self.fmtText.split(' ')\n",
        "\n",
        "        # Create dictionary\n",
        "        freqMap = {}\n",
        "        for word in set(wordList): # use set to remove duplicates in list\n",
        "            freqMap[word] = wordList.count(word)\n",
        "\n",
        "        return freqMap\n",
        "\n",
        "    def freqOf(self,word):\n",
        "        # get frequency map\n",
        "        freqDict = self.freqAll()\n",
        "\n",
        "        if word in freqDict:\n",
        "            return freqDict[word]\n",
        "        else:\n",
        "            return 0"
      ],
      "metadata": {
        "id": "aoljqd1Qw6Ou"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyzed = TextAnalyzer(givenstring)"
      ],
      "metadata": {
        "id": "3uF9d8w1w_T-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Formatted Text:\", analyzed.fmtText)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pW_vMs2nxW2u",
        "outputId": "8f0aeebc-9553-4d3c-daea-f6e8ffc0b442"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formatted Text: lorem ipsum dolor diam amet consetetur lorem magna sed diam nonumy eirmod tempor diam et labore et diam magna et diam amet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freqMap = analyzed.freqAll()\n",
        "print(freqMap)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4m4KgwT9xZqH",
        "outputId": "31cff20b-dcd2-4e03-dd51-408fb5a3e6d0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'nonumy': 1, 'labore': 1, 'amet': 2, 'magna': 2, 'eirmod': 1, 'tempor': 1, 'dolor': 1, 'et': 3, 'ipsum': 1, 'consetetur': 1, 'sed': 1, 'diam': 5, 'lorem': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"lorem\"\n",
        "frequency = analyzed.freqOf(word)\n",
        "print(\"The word\",word,\"appears\",frequency,\"times.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUodKkPRxd2J",
        "outputId": "15ee413d-2370-46d6-b53e-6100b09e135f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The word lorem appears 2 times.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c2XItQkzxhWd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}